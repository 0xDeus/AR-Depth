{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pyquaternion import Quaternion\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "#### Dependencies: \n",
    "- OpenCV 2\n",
    "- NumPy\n",
    "- pyquaternion (`pip install pyquaternion`)\n",
    "\n",
    "#### First, make sure it runs on the test sequence:\n",
    "- Above, press `Cell > Run All`\n",
    "- Make sure the 'output' folder is populated with frames, and the depth maps look reasonable\n",
    "    \n",
    "#### Then, you can input your own data:\n",
    "- Replace the values of the three variables below\n",
    "  - **input_frames**: the path to the folder which contains your video frames\n",
    "  - **input_recon**: the path to the folder which contains your sparse reconstruction. For input format, we use the COLMAP format defined here (https://colmap.github.io/format.html). This folder should contain three files: `points2D.txt`, `images.txt`, and `cameras.txt`. Since the COLMAP format does not natively include information about whether or not a frame is a keyframe (since it's not originally intended for SLAM systems), we interpret this information from the POINTS2D[] in `images.txt`. That is, if a given image has a nonzero number of POINTS2D, we assume it is a keyframe.\n",
    "  - **output_folder**: the path to the folder where you want the output saved\n",
    "\n",
    "This Python notebook is intended as a reference implementation for research purposes. The code is an unoptimized version of the full method, and Python is slow, so performance will be worse than what is reported in the paper. Please refer to the paper for more accurate timing results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_frames = \"sample_data/frames/\"\n",
    "input_colmap = \"sample_data/reconstruction/\"\n",
    "output_folder = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm parameters. See the paper for details.\n",
    "\n",
    "tau_high = 0.9\n",
    "tau_low = 0.1\n",
    "tau_flow = 0.5\n",
    "k_I = 5\n",
    "k_T = 7\n",
    "k_F = 31\n",
    "lambda_d = 1\n",
    "lambda_t = 0.01\n",
    "lambda_s = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simplified COLMAP importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reconstruction:\n",
    "    cameras = {}\n",
    "    views = {}\n",
    "    points3d = {}\n",
    "    image_folder = \"\"\n",
    "    \n",
    "    def ViewIds(self):\n",
    "        return list(self.views.keys())\n",
    "    \n",
    "    def GetNeighboringKeyframes(self, view_id):\n",
    "        previous_keyframe = -1\n",
    "        next_keyframe = -1\n",
    "        for idx in range(view_id - 1, 0, -1):\n",
    "            if self.views[idx].IsKeyframe():\n",
    "                previous_keyframe = idx\n",
    "                break\n",
    "        for idx in range(view_id + 1, len(self.views) - 1):\n",
    "            if self.views[idx].IsKeyframe():\n",
    "                next_keyframe = idx\n",
    "                break\n",
    "        if previous_keyframe < 0 or next_keyframe < 0:\n",
    "            return np.array()\n",
    "        return np.array([previous_keyframe, next_keyframe])\n",
    "    \n",
    "    def GetReferenceFrames(self, view_id):\n",
    "        kf = self.GetNeighboringKeyframes(view_id)\n",
    "        dist = np.linalg.norm(self.views[kf[1]].Position() -\\\n",
    "                              self.views[kf[0]].Position()) / 2\n",
    "        pos = self.views[view_id].Position()\n",
    "        ref = []\n",
    "        for idx in range(view_id + 1, len(self.views) - 1):\n",
    "            if (np.linalg.norm(self.views[kf[1]].Position() -\\\n",
    "                              self.views[kf[0]].Position()) > dist):\n",
    "                ref.append(idx)\n",
    "                break\n",
    "        for idx in range(view_id - 1, 0, -1):\n",
    "            if (np.linalg.norm(self.views[kf[1]].Position() -\\\n",
    "                              self.views[kf[0]].Position()) > dist):\n",
    "                ref.append(idx)\n",
    "                break\n",
    "        return ref\n",
    "\n",
    "    def GetImage(self, view_id):\n",
    "        return self.views[view_id].GetImage(self.image_folder)\n",
    "    \n",
    "    def GetSparseDepthMap(self, frame_id):\n",
    "        camera = self.cameras[self.views[frame_id].camera_id]\n",
    "        view = self.views[frame_id]\n",
    "        view_pos = view.Position()\n",
    "        depth_map = np.zeros((camera.width, camera.height), dtype=np.float32)\n",
    "        for point_id, coord in view.points2d.items():\n",
    "            pos3d = self.points3d[point_id].position3d\n",
    "            depth = np.linalg.norm(pos3d - view_pos)\n",
    "            depth_map[int(coord[0]), int(coord[1])] = depth\n",
    "        return depth_map\n",
    "    \n",
    "    def Print(self):\n",
    "        print \"Found \" + str(len(self.views)) + \" cameras.\"\n",
    "        for id in self.cameras:\n",
    "            self.cameras[id].Print()\n",
    "        print \"Found \" + str(len(self.views)) + \" frames.\"\n",
    "        for id in self.views:\n",
    "            self.views[id].Print()\n",
    "\n",
    "class Point:\n",
    "    id = -1\n",
    "    position3d = np.zeros(3, float)\n",
    "            \n",
    "class Camera:\n",
    "    id = -1\n",
    "    width = 0\n",
    "    height = 0\n",
    "    focal = np.zeros(2,float)\n",
    "    principal = np.zeros(2,float)\n",
    "    model = \"\"\n",
    "    \n",
    "    def Print(self):\n",
    "        print \"Camera \" + str(self.id)\n",
    "        print \"-Image size: (\" + str(self.width) + \\\n",
    "            \", \" + str(self.height) + \")\" \n",
    "        print \"-Focal: \" + str(self.focal) \n",
    "        print \"-Model: \" + self.model\n",
    "        print \"\"\n",
    "\n",
    "class View:\n",
    "    id = -1\n",
    "    orientation = Quaternion()\n",
    "    translation = np.zeros(3, float)\n",
    "    points2d = {}\n",
    "    camera_id = -1\n",
    "    name = \"\"\n",
    "    \n",
    "    def IsKeyframe(self):\n",
    "        return len(self.points2d) > 0\n",
    "    \n",
    "    def Rotation(self):\n",
    "        return self.orientation.rotation_matrix\n",
    "    \n",
    "    def Position(self):\n",
    "        return self.orientation.rotate(self.translation)\n",
    "    \n",
    "    def GetImage(self, image_folder):\n",
    "        mat = cv2.imread(image_folder + \"/\" + self.name)\n",
    "        # Check that we loaded correctly.\n",
    "        assert mat is not None, \\\n",
    "            \"Image \" + self.name + \" was not found in \" \\\n",
    "            + image_folder\n",
    "        return mat\n",
    "    \n",
    "    def Print(self):\n",
    "        print \"Frame \" + str(self.id) + \": \" + self.name\n",
    "        print \"Rotation: \\n\" + \\\n",
    "            str(self.Rotation())\n",
    "        print \"Position: \\n\" + \\\n",
    "            str(self.Position())\n",
    "        print \"\"\n",
    "        \n",
    "def ReadColmapCamera(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    cameras = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            camera = Camera()\n",
    "            camera.id = int(tokens[0])\n",
    "            camera.model = tokens[1]\n",
    "            # Currently we're assuming that the camera model\n",
    "            # is in the SIMPLE_RADIAL format\n",
    "            assert(camera.model == \"PINHOLE\")\n",
    "            camera.width = int(tokens[2])\n",
    "            camera.height = int(tokens[3])\n",
    "            camera.focal[0] = float(tokens[4])\n",
    "            camera.focal[1] = float(tokens[5])\n",
    "            camera.principal[0] = float(tokens[6])\n",
    "            camera.principal[1] = float(tokens[7])\n",
    "            cameras[camera.id] = camera\n",
    "        line = file.readline()\n",
    "    return cameras;\n",
    "\n",
    "def ReadColmapImages(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    views = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            view = View()\n",
    "            view.id = int(tokens[0])\n",
    "            view.orientation.w = float(tokens[1])\n",
    "            view.orientation.x = float(tokens[2])\n",
    "            view.orientation.y = float(tokens[3])\n",
    "            view.orientation.z = float(tokens[4])\n",
    "            view.translation[0] = float(tokens[5])\n",
    "            view.translation[1] = float(tokens[6])\n",
    "            view.translation[2] = float(tokens[7])\n",
    "            view.camera_id = int(tokens[8])\n",
    "            view.name = tokens[9]\n",
    "            line = file.readline()\n",
    "            tokens = line.split()\n",
    "            view.points2d = {}\n",
    "            for idx in range(0, len(tokens) / 3):\n",
    "                point_id = int(tokens[idx * 3 + 2])\n",
    "                coord = np.array([float(tokens[idx * 3 + 0]), \\\n",
    "                         float(tokens[idx * 3 + 1])])\n",
    "                view.points2d[point_id] = coord\n",
    "            views[view.id] = view\n",
    "            # Read the observations...\n",
    "        line = file.readline()\n",
    "    return views\n",
    "           \n",
    "def ReadColmapPoints(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    line = file.readline()\n",
    "    points = {}\n",
    "    while (line):\n",
    "        if (line[0] != '#'):\n",
    "            tokens = line.split()\n",
    "            point = Point()\n",
    "            point.id = int(tokens[0])\n",
    "            point.position3d = np.array([float(tokens[1]), \\\n",
    "                                        float(tokens[2]), \\\n",
    "                                        float(tokens[3])])\n",
    "            points[point.id] = point\n",
    "            \n",
    "        line = file.readline()\n",
    "    return points\n",
    "        \n",
    "            \n",
    "    \n",
    "def ReadColmap(poses_folder, images_folder):\n",
    "    # Read the cameras (intrinsics)\n",
    "    recon = Reconstruction()\n",
    "    recon.image_folder = images_folder\n",
    "    recon.cameras = ReadColmapCamera(poses_folder + \"/cameras.txt\")\n",
    "    recon.views = ReadColmapImages(poses_folder + \"/images.txt\")\n",
    "    recon.points3d = ReadColmapPoints(poses_folder + \"/points3D.txt\")\n",
    "    print \"Number of points: \" + str(len(recon.points3d))\n",
    "    print \"Number of frames: \" + str(len(recon.views))\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The densification code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetFlow(image1, image2):\n",
    "    flow = cv2.calcOpticalFlowFarneback(\\\n",
    "        cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY),\\\n",
    "        cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY),\\\n",
    "        0.5, 3, 100, 100, 7, 1.5, 0)\n",
    "    a,b,c = cv2.split(image1)\n",
    "    return cv2.merge((a,b))\n",
    "\n",
    "def GetFlowGradientMagnitude(flow):\n",
    "    x1,x2 = cv2.split(cv2.Sobel(flow,cv2.CV_64F,1,0,ksize=5))\n",
    "    y1,y2 = cv2.split(cv2.Sobel(flow,cv2.CV_64F,0,1,ksize=5))\n",
    "    flow_grad_x = np.maximum(x1,x2)\n",
    "    flow_grad_y = np.maximum(y1,y2)\n",
    "    flow_grad_magnitude = cv2.sqrt((flow_grad_x * flow_grad_x) \\\n",
    "                                   + (flow_grad_y * flow_grad_y))\n",
    "    reliability = np.zeros((flow.shape[0], flow.shape[1]))\n",
    "    return flow_grad_magnitude, reliability\n",
    "\n",
    "def GetImageGradientMagnitude(image):\n",
    "    xr,xg,xb = cv2.split(cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5))\n",
    "    yr,yg,yb = cv2.split(cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5))\n",
    "    img_grad_x = np.maximum(xr,xg,xb)\n",
    "    img_grad_y = np.maximum(yr,yg,yb)\n",
    "    img_grad_magnitude = cv2.sqrt((img_grad_x * img_grad_x) \\\n",
    "                                  + (img_grad_y * img_grad_y))\n",
    "    return img_grad_magnitude\n",
    "\n",
    "def GetSoftEdges(image, flows):\n",
    "\n",
    "    img_grad_magnitude = GetImageGradientMagnitude(image)\n",
    "    flow_gradient_magnitude = np.zeros(img_gradient_magnitude.shape)\n",
    "    max_reliability = np.zeros(img_gradient_magnitude.shape)\n",
    "    for flow in flows:\n",
    "        magnitude, reliability = GetFlowGradientMagnitude(flow)\n",
    "        flow_gradient_magnitude[reliability > max_reliability] = magnitude\n",
    "    \n",
    "    flow_grad_magnitude = \\\n",
    "        cv2.GaussianBlur(flow_grad_magnitude,(k_F, k_F),0)\n",
    "    return flow_grad_magnitude * (img_grad_magnitude)\n",
    "    \n",
    "def NonMaxSuppression(gradient):\n",
    "    TG22 = 13573\n",
    "    \n",
    "    gx,gy = cv2.split(gradient * (2**15))\n",
    "    mag = cv2.sqrt((gx * gx) \\\n",
    "                    + (gy * gy))\n",
    "    suppressed = np.zeros(mag.shape)\n",
    "    for x in range(1, gradient.shape[0] - 1):\n",
    "        for y in range(1, gradient.shape[1] - 1):\n",
    "            ax = int(abs(gx[x,y]))\n",
    "            ay = int(abs(gy[x,y])) << 15\n",
    "            tg22x = ax * TG22\n",
    "            m = mag[x,y]\n",
    "            if (ay < tg22x):\n",
    "                if (m > mag[x,y-1] and\\\n",
    "                   m >= mag[x,y+1]):\n",
    "                    suppressed[x,y] = m\n",
    "            else:\n",
    "                tg67x = tg22x + (ax << 16)\n",
    "                if (ay > tg67x):\n",
    "                    if (m > mag[x+1,y] and m >= mag[x-1,y]):\n",
    "                        suppressed[x,y] = m\n",
    "                else:\n",
    "                    if (int(gx[x,y]) ^ int(gy[x,y]) < 0):\n",
    "                        if (m > mag[x-1,y+1] and m >= mag[x+1,y-1]):\n",
    "                            suppressed[x,y] = m\n",
    "                    else:\n",
    "                        if (m > mag[x-1,y-1] and m > mag[x+1,y+1]):\n",
    "                            suppressed[x,y] = m\n",
    "    return suppressed\n",
    "                    \n",
    "    \n",
    "def Canny(soft_edges, image):\n",
    "    image = cv2.GaussianBlur(image, (k_I, k_I), 0)\n",
    "    xr,xg,xb = cv2.split(cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5))\n",
    "    yr,yg,yb = cv2.split(cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5))\n",
    "    image_gradient = cv2.merge((np.maximum(xr,xg,xb),np.maximum(yr,yg,yb)))\n",
    "    print image_gradient.shape\n",
    "    gradient_mag = NonMaxSuppression(image_gradient)\n",
    "    return gradient_mag > 0\n",
    "    \n",
    "def DensifyFrame(sparse_points, hard_edges, soft_edges, last_depth_map):\n",
    "    w = edges.shape[0]\n",
    "    h = edges.shape[1]\n",
    "    num_pixels = w * h\n",
    "    A = scipy.sparse.dok_matrix((num_pixels * 3, num_pixels), dtype=np.float32)\n",
    "    b = np.zeros(num_pixels, dtype=np.float32)\n",
    "    num_entries = 0\n",
    "    \n",
    "    smoothness = np.maximum(1 - soft_edges, 0)\n",
    "    \n",
    "    for row in range(1,h - 1):\n",
    "        for col in range(1,w - 1):\n",
    "            # Add the data constraints\n",
    "            if (sparse_points[col,row] > 0):\n",
    "                A[num_entries, col + row * w] = lambda_d\n",
    "                b[col + row * w] = sparse_points[col,row]\n",
    "                num_entries += 1\n",
    "            elif (last_depth_map.size > 0 and last_depth_map[col,row] > 0):\n",
    "                A[num_entries, col + row * w] = lambda_t\n",
    "                b[col + row * w] = last_depth_map[col,row]\n",
    "                num_entries += 1\n",
    "    \n",
    "            # Add the smoothness constraints\n",
    "            smoothness_weight = lambda_s * min(smoothness[col,row], \\\n",
    "                                               smoothness[col-1, row])\n",
    "            if (int(hard_edges[col,row]) ^ int(hard_edges[col - 1, row]) == 0):\n",
    "                A[num_entries, (col - 1) + row * w] = smoothness_weight\n",
    "                A[num_entries, col + row * w] = -smoothness_weight\n",
    "                num_entries += 1\n",
    "            \n",
    "            smoothness_weight = lambda_s * min(smoothness[col,row], \\\n",
    "                                               smoothness[col, row - 1])\n",
    "            if (int(hard_edges[col,row]) ^ int(hard_edges[col, row - 1]) == 0):\n",
    "                A[num_entries, col + (row - 1) * w] = smoothness_weight\n",
    "                A[num_entries, col + (row - 1) * w] = -smoothness_weight\n",
    "                num_entries += 1\n",
    "    \n",
    "    # Solve the system\n",
    "    x = scipy.sparse.linalg.cg(A.transpose() * A, A.transpose() * b)\n",
    "    depth = last_depth_map.clone()\n",
    "    \n",
    "    # Copy back the pixels\n",
    "    for row in range(1,h):\n",
    "        for col in range(1,w):\n",
    "            depth[col,row] = x[col + row * w]\n",
    "    return depth\n",
    "\n",
    "def TemporalMedian(depth_maps):\n",
    "    lists = {}\n",
    "    depth_map = depth_maps.itervalues().next().clone()\n",
    "    for row in range(0,h):\n",
    "        for col in range(0,w):\n",
    "            values = []\n",
    "            for img in depth:\n",
    "                if (img[col,row] > 0):\n",
    "                    values.append(img[col, row])\n",
    "            depth_map[col,row] = np.median(np.array(values))\n",
    "    return depth_map\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = ReadColmap(input_colmap, input_frames)\n",
    "\n",
    "last_depths = []\n",
    "last_depth = np.array([])\n",
    "for frame in recon.ViewIds():\n",
    "    print \"Processing frame \" + recon.views[frame].name\n",
    "    kfs = recon.GetReferenceFrames(frame)\n",
    "    if (len(kfs) == 0):\n",
    "        continue\n",
    "    base_img = recon.GetImage(frame)\n",
    "    flows = []\n",
    "    for kf in kfs:\n",
    "        img = recon.GetImage(kf) \n",
    "        flows.append(GetFlow(base_img, img))\n",
    "    soft_edges = GetSoftEdges(img1, flows)\n",
    "    edges = Canny(softedges, img1)\n",
    "    depth = DensifyFrame(recon.GetSparseDepthMap(kf[0]), edges, \\\n",
    "                         soft_edges, last_depth)\n",
    "    last_depths.append(depth)\n",
    "    if (len(last_depths) > k_T):\n",
    "        last_depths.pop(0)\n",
    "    filtered_depth = TemporalFilter(last_depths)\n",
    "    plt.imsave(output_folder + \"/\" + recon.views[frame].name, \\\n",
    "               filtered_depth)\n",
    "    last_depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
